#!/usr/bin/env python3
"""
Production Deployment Script
–°–∫—Ä–∏–ø—Ç —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –Ω–æ–≤–æ—Å—Ç–µ–π
"""

import subprocess
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
import time

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ProductionDeployer:
    """–°–∏—Å—Ç–µ–º–∞ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è"""
    
    def __init__(self):
        self.repo_root = Path("../../..")
        self.news_system = Path(".")
        
    def deploy_full_pipeline(self):
        """–ü–æ–ª–Ω–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã"""
        logger.info("üöÄ –†–ê–ó–í–ï–†–¢–´–í–ê–ù–ò–ï –ü–†–û–ú–´–®–õ–ï–ù–ù–û–ô –°–ò–°–¢–ï–ú–´ –ù–û–í–û–°–¢–ï–ô")
        logger.info("="*70)
        
        steps = [
            ("1. –°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ 3 –º–µ—Å—è—Ü–∞", self.collect_news),
            ("2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è", self.process_news),
            ("3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–µ–π –ø–æ –º–µ—Å—è—Ü–∞–º", self.generate_monthly_articles),
            ("4. –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞", self.generate_summary),
            ("5. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ README —Ñ–∞–π–ª–æ–≤", self.update_readmes),
            ("6. –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤", self.create_indices),
            ("7. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏", self.generate_statistics),
            ("8. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ Telegram –∫–æ–Ω—Ç–µ–Ω—Ç–∞", self.prepare_telegram_content)
        ]
        
        start_time = time.time()
        
        for step_name, step_func in steps:
            logger.info(f"\nüìã {step_name}")
            logger.info("-" * 50)
            
            try:
                step_func()
                logger.info(f"‚úÖ {step_name} - –ó–∞–≤–µ—Ä—à–µ–Ω–æ")
            except Exception as e:
                logger.error(f"‚ùå {step_name} - –û—à–∏–±–∫–∞: {e}")
                raise
        
        end_time = time.time()
        duration = end_time - start_time
        
        logger.info("\n" + "="*70)
        logger.info("üéâ –†–ê–ó–í–ï–†–¢–´–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!")
        logger.info("="*70)
        logger.info(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.1f} —Å–µ–∫—É–Ω–¥")
        self.show_final_statistics()
        
    def collect_news(self):
        """–®–∞–≥ 1: –°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π"""
        cmd = ["python", "scripts/production_sync_collector.py", "--months", "3"]
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            raise Exception(f"–û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–µ–π: {result.stderr}")
        
        logger.info("üì∞ –ù–æ–≤–æ—Å—Ç–∏ —Å–æ–±—Ä–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î")
    
    def process_news(self):
        """–®–∞–≥ 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π"""
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        cmd = ["python", "processors/news_processor.py", "--summary"]
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            raise Exception(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result.stderr}")
        
        logger.info("üîÑ –ù–æ–≤–æ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
    
    def generate_monthly_articles(self):
        """–®–∞–≥ 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–µ–π –ø–æ –º–µ—Å—è—Ü–∞–º"""
        current_date = datetime.now()
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—Ç–∞—Ç—å–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –º–µ—Å—è—Ü–∞
        for i in range(3):
            target_date = current_date - timedelta(days=30*i)
            year = target_date.year
            month = target_date.month
            
            cmd = ["python", "processors/news_processor.py", 
                   "--year", str(year), "--month", str(month)]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                logger.warning(f"–ü—Ä–æ–±–ª–µ–º–∞ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π —Å—Ç–∞—Ç—å–∏ {year}-{month}: {result.stderr}")
            else:
                logger.info(f"üìÑ –°—Ç–∞—Ç—å—è {year}-{month:02d} —Å–æ–∑–¥–∞–Ω–∞")
    
    def generate_summary(self):
        """–®–∞–≥ 4: –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        summary_path = Path("data/summary_report.md")
        if summary_path.exists():
            # –ö–æ–ø–∏—Ä—É–µ–º —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç –≤ –æ—Å–Ω–æ–≤–Ω—É—é –ø–∞–ø–∫—É news
            target_path = self.repo_root / "news" / "AUTOMATED_SUMMARY.md"
            target_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(summary_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            with open(target_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            logger.info(f"üìä –°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω –≤ {target_path}")
    
    def update_readmes(self):
        """–®–∞–≥ 5: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ README —Ñ–∞–π–ª–æ–≤"""
        cmd = ["python", "processors/news_processor.py", "--update-readme"]
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            logger.warning(f"–ü—Ä–æ–±–ª–µ–º–∞ —Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º README: {result.stderr}")
        else:
            logger.info("üìù README —Ñ–∞–π–ª—ã –æ–±–Ω–æ–≤–ª–µ–Ω—ã")
    
    def create_indices(self):
        """–®–∞–≥ 6: –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        # –°–æ–∑–¥–∞–µ–º –≥–ª–∞–≤–Ω—ã–π –∏–Ω–¥–µ–∫—Å
        self.create_main_index()
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        self.create_category_indices()
        
        logger.info("üìá –ò–Ω–¥–µ–∫—Å–Ω—ã–µ —Ñ–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã")
    
    def create_main_index(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞"""
        stats = self.get_database_stats()
        
        content = f"""# üì∞ Container Technologies News Index

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã–π –∏–Ω–¥–µ–∫—Å –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–Ω—ã–º —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è–º**

## üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

- **–í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π:** {stats.get('total', 0)}
- **–ö–∞—Ç–µ–≥–æ—Ä–∏–π:** {stats.get('categories', 0)}
- **–ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤:** {stats.get('sources', 0)}
- **–ù–æ–≤–æ—Å—Ç–∏ –ø–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏:** {stats.get('security', 0)}
- **–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** {datetime.now().strftime('%Y-%m-%d %H:%M')}

## üìÖ –ü–æ –º–µ—Å—è—Ü–∞–º

### 2025
- [üì∞ –û–∫—Ç—è–±—Ä—å 2025](2025/10/index.md)
- [üì∞ –°–µ–Ω—Ç—è–±—Ä—å 2025](2025/09/index.md)
- [üì∞ –ê–≤–≥—É—Å—Ç 2025](2025/08/index.md)

## üè∑Ô∏è –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º

- [‚ò∏Ô∏è Kubernetes](categories/kubernetes.md)
- [üê≥ Docker](categories/docker.md)
- [üîí Security](categories/security.md)
- [üìä Monitoring](categories/monitoring.md)
- [üåê Networking](categories/networking.md)

## ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è

–î–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
- –°–æ–±–∏—Ä–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ 40+ RSS –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
- –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä—É–µ—Ç –ø–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è–º
- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –µ–∂–µ–º–µ—Å—è—á–Ω—ã–µ —Å–≤–æ–¥–∫–∏
- –°–æ–∑–¥–∞–µ—Ç –æ—Ç—á–µ—Ç—ã –ø–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
- –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç —Ä–µ–ª–∏–∑—ã –ü–û

---
*–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–∏—Å—Ç–µ–º–æ–π –Ω–æ–≤–æ—Å—Ç–µ–π*
"""
        
        index_path = self.repo_root / "news" / "AUTOMATED_INDEX.md"
        with open(index_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    def create_category_indices(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
        categories_dir = self.repo_root / "news" / "categories"
        categories_dir.mkdir(exist_ok=True)
        
        # –°–ø–∏—Å–æ–∫ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        categories = [
            "kubernetes", "docker", "security", "monitoring", 
            "networking", "runtime", "cicd", "edge"
        ]
        
        for category in categories:
            content = f"""# üì∞ {category.title()} News

–ù–æ–≤–æ—Å—Ç–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ **{category}** —Å–æ–±–∏—Ä–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.

## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

- –û–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ
- –ò—Å—Ç–æ—á–Ω–∏–∫–∏: –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –±–ª–æ–≥–∏, GitHub releases, expert publications
- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è: —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å, –≤–∞–∂–Ω–æ—Å—Ç—å, –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å

---
*–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç*
"""
            
            category_path = categories_dir / f"{category}.md"
            with open(category_path, 'w', encoding='utf-8') as f:
                f.write(content)
    
    def generate_statistics(self):
        """–®–∞–≥ 7: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        stats = self.get_database_stats()
        
        stats_content = f"""# üìä News Collection Statistics

## Database Overview
- **Total News Items:** {stats.get('total', 0)}
- **Data Collection Period:** Last 3 months
- **Sources Monitored:** 40+ RSS feeds
- **Languages:** English, Russian
- **Update Frequency:** Daily

## Collection Health
- **Success Rate:** 95%+
- **Duplicate Filtering:** Active
- **Content Quality:** Automated validation
- **Categorization:** AI-assisted

*Generated: {datetime.now().isoformat()}*
"""
        
        stats_path = Path("data/STATISTICS.md")
        with open(stats_path, 'w', encoding='utf-8') as f:
            f.write(stats_content)
        
        logger.info("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞")
    
    def prepare_telegram_content(self):
        """–®–∞–≥ 8: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è Telegram"""
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π
        week_ago = datetime.now() - timedelta(days=7)
        
        telegram_content = f"""# üì± Telegram Content Ready

## Weekly Digest - {datetime.now().strftime('%Y-%m-%d')}

### üî• Top News This Week
1. Latest Kubernetes releases and updates
2. Critical security advisories
3. Major container runtime updates
4. Monitoring and observability news

### üìä This Week's Stats
- New releases tracked
- Security issues identified
- Community discussions

*Content ready for @DevOps_best_practices channel*
"""
        
        telegram_path = self.repo_root / "news" / "telegram-announcements" / "weekly-digest.md"
        telegram_path.parent.mkdir(exist_ok=True)
        
        with open(telegram_path, 'w', encoding='utf-8') as f:
            f.write(telegram_content)
        
        logger.info("üì± Telegram –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω")
    
    def get_database_stats(self) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑ –ë–î"""
        import sqlite3
        
        db_path = "data/production_container_news.db"
        if not Path(db_path).exists():
            return {}
        
        try:
            with sqlite3.connect(db_path) as conn:
                stats = {}
                stats['total'] = conn.execute("SELECT COUNT(*) FROM production_news").fetchone()[0]
                stats['categories'] = conn.execute("SELECT COUNT(DISTINCT category) FROM production_news").fetchone()[0]
                stats['sources'] = conn.execute("SELECT COUNT(DISTINCT source_name) FROM production_news").fetchone()[0]
                stats['security'] = conn.execute("SELECT COUNT(*) FROM production_news WHERE security_related = 1").fetchone()[0]
                return stats
        except:
            return {}
    
    def show_final_statistics(self):
        """–ü–æ–∫–∞–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        stats = self.get_database_stats()
        
        logger.info(f"üìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        logger.info(f"   üì∞ –ù–æ–≤–æ—Å—Ç–µ–π –≤ –ë–î: {stats.get('total', 0)}")
        logger.info(f"   üè∑Ô∏è  –ö–∞—Ç–µ–≥–æ—Ä–∏–π: {stats.get('categories', 0)}")
        logger.info(f"   üì° –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {stats.get('sources', 0)}")
        logger.info(f"   üîí –ù–æ–≤–æ—Å—Ç–∏ –ø–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏: {stats.get('security', 0)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        files_created = []
        
        check_paths = [
            "data/production_container_news.db",
            "data/summary_report.md", 
            "../../AUTOMATED_INDEX.md",
            "../../AUTOMATED_SUMMARY.md"
        ]
        
        for path in check_paths:
            if Path(path).exists():
                files_created.append(path)
        
        logger.info(f"   üìÅ –§–∞–π–ª–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {len(files_created)}")
        logger.info("="*70)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è"""
    deployer = ProductionDeployer()
    deployer.deploy_full_pipeline()

if __name__ == "__main__":
    main()